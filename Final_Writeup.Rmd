---
title: "Predicting Marijuana Use Disorder: A Machine Learning Approach"
author: "Jiashu Liu"
date: "2024-06-16"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
    theme: lumen
    keep_md: true
    df_print: paged
    code_download: true
    code_folding: hide
    css: styles.css
bibliography: references.bib
font-family: "Times New Roman"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE, error = FALSE, warning = FALSE)
```

```{r load packages}
# Load libraries
library(tidyverse)
library(dplyr)
library(readr)
library(ggplot2)
library(httr)
library(jsonlite)
library(foreach)
library(psych)
library(pandoc)
library(patchwork)
library(gt) # for better table output
library(gridExtra)
library(ROCR)
library(ranger)
library(randomForest)
library(caret)
library(e1071)
library(nnet)
library(dummy)
library(gbm)
library(glmnet)
```

# Introduction 

Marijuana has gained increasing prevalence in the US. As of April 2024, 38 states have legalized the medical use of marijuana products, and among these, 24 states have also legalized recreational marijuana [@ncsl]. The pros and cons of marijuana legalization remain an ongoing debate. Some studies suggest that the increasing popularity of marijuana products is associated with an increasing risk of developing marijuana use disorder[@compton2019]. In 2012-2013, among the 9.52% of US adults who used marijuana, 2.9% had a diagnosis of DSM-IV marijuana use disorder. In other words, nearly 3 out of every 10 marijuana users had a diagnosis of a marijuana use disorder [@hhs2023]. A more recent study suggests that about 27% of lifetime cannabis users transition to marijuana use disorder based on the DSM-5 diagnosis criteria [@feingold2020]. Given the prevalence of marijuana products and the high risk of developing marijuana use disorder, it is imperative to identify and predict the associated risk factors. 

Previous literature has employed machine learning frameworks to research substance use disorder. For example, in a study by Acion et al. (2017)[@acion2017], researchers used several machine learning models, including logistic regression, Random Forest (RF), Artificial Neural Network (ANN), and Super Learning (SL), as prediction tools for the success of substance use disorder treatment.

The goal of this project is to investigate the socio-demographic factors potentially associated with the risk of a marijuana user developing substance use disorder using a machine learning approach. By leveraging advanced machine learning models, I aim to identify key predictors and improve our understanding of the factors contributing to marijuana use disorder. The methodology I used is based on Rajapaksha et al. (2020)[@rajapaksha2020], in which the researchers employed LASSO, KNN, Random Forest, SVM, and Gradient Boosting to estimate the chance of developing SUD based on various demographic, behavioral, psychiatric, and cognitive risk factors. 

In this project, I will use logistic regression, Lasso logistic regression, Random Forest, and Gradient Boosting The overall performance of the machine learning models will be evaluated using the area under the receiver operating characteristic curve (AUC), overall accuracy (i.e., the proportion of overall correct classifications), sensitivity (i.e., the proportion of correct classifications among the SUD instances/true positives), and specificity (i.e., the proportion of correct classifications among the non-SUD instances/true negatives). By comparing these metrics, I aim to determine the most effective machine learning model for predicting the risk of developing marijuana use disorder. This project can inform prevention and intervention strategies, ultimately aiding in addressing the challenges posed by increased marijuana use.

# Data

The data utilized in this project comes from the 2022 National Survey on Drug Use and Health (NSDUH) Releases. This survey provides nationally representative data on tobacco, alcohol, and drug use; substance use disorders; mental health issues; and the receipt of substance use and mental health treatment among the civilian, non-institutionalized population aged 12 and older in the United States. Compared to the 2021 NSDUH data, the 2022 version updated questions related to substance use treatment and mental health treatment, vaping of nicotine and marijuana, different methods of marijuana use, and the use of illegally made fentanyl (IMF). Most importantly, the 2022 NSDUH data is less affected by the COVID-19 pandemic than the 2021 data, which was a significant consideration in our previous project. In-person data collection for the 2022 NSDUH was only restricted in January 2022, resulting in a higher proportion of in-person interviews in 2022 compared to 2021.

```{r load datasets}
# Load data -- NSDUH 2022
load("/Users/jiashuliu/Desktop/Projects/substance_use_disorder/data/NSDUH_2022.RData")
sud_2022 <- read_csv("/Users/jiashuliu/Desktop/Projects/substance_use_disorder/data/sud_2022.csv")
```

#### Outcome Variable 

The outcome variable SUD_MJ is based on the DSM-5 Diagnostic Criteria for diagnosing and classifying substance use disorders. I reviewed questions from the marijuana use disorder section of the 2022 NSDUH data and identified the most relevant questions corresponding to the DSM-5 criteria. An SUD_MJ value of 1 indicates that the respondent has some level of marijuana use disorder, while a value of 0 indicates the absence of such a disorder. 

```{r construct outcome variable}
# If any of the "udmj" variables have a value of 1, we set SUD_MJ as 1, otherwise SUD_MJ is 0.
NSDUH_2022_full <- NSDUH_2022 %>%
  mutate(across(starts_with("udmj"), 
                ~if_else(. %in% c(1, 2), 
                         if_else(. == 1, 1, 0), 
                         NA))) %>% 
  select(-"udmjavwothr") %>% 
  mutate(SUD_MJ = rowSums(select(., starts_with("udmj")), na.rm = TRUE)>=1, 
         SUD_MJ = if_else(SUD_MJ, 1, 0))
```

#### Predictors

A previous study indicates that the prevalence of marijuana use disorder varies among different age groups, races, and between people with and without mental health problems [@santaella2019]. In this project,  there are 14 selected predictors, including age, sex, race, health status, marital status, highest degree obtained, school attendance, employment status, number of people in the household, number of children under 18 in the household, number of elderly people over 65 in the household, health insurance status, family income level, and mental health status.

All the socio-demographic variables in the survey are provided as categorical variables with various levels. I followed the methodology used in the original survey data but reorganized some variables into more general levels to make the data easier to analyze and interpret. For example, the predictor age (AGE3 in the survey data) originally had 10 levels. I consolidated these into four levels: 1 represents adolescents under age 18, 2 represents young adults aged 18 to 29, 3 indicates middle-aged individuals aged 30 to 64, and 4 represents elderly individuals aged 65 and older. The final cleaned dataset 

```{r}
codebook = data.frame(Variable = c("Age", "Sex", "Race", "Health", "Marital", "Degree", "Now going to school or not?", "Employment", "Persons in Household", "Kids age<18 in Household", "Elderly age>65 in Household", "Health Insurance", "Income: family income", "Mentalhealth: combined score of K6 questions"), 
                      Meaning = c("1=Adolescent: 18-, 2=Young Adult: 18-29, 3=Middle Age: 30-64, 4=Elderly: 65+", "0=Female, 1=Male", "1=NonHisp White, 2=NonHisp Black/Afr Am, 3=NonHisp Native Am/AK Native, 4=NonHisp Native HI/Other Pac Isl, 5=NonHisp Asian, 6=NonHisp more than one race, 7=Hispanic", "0=w/o health problem: excellent/very good/good, 1=with health problem: fair/poor", "0=never been married/cannot married<=14, 1=married, 2=widowed/divorced/separated", "1=w/o high school, 2=high school degree, 3=associate's degree/college graduate or higher", "1/11 = now going to school,  0=No, other is NA", "1=employed full time, 2=employed part time, 3=unemployed, 4=Other(incl. not in labor force)", "range 1-5, 6=6 or more people in household", "0=No children under 18 , 1=One child under 18, 2=Two children under 18, 3=Three or more children under 18.", "0=No people 65 or older in household, 1 = One person 65 or older in household, 2 = Two or more people 65 or older in household", "0=w/o health insurance, 1=health insurance", "1=poverty:20000-, 2=middle:74999-, 3=wealth:75000+", "range = 0 - 24, na:Aged 12-17"))
codebook %>%
  gt() %>%
  tab_header(
    title = md("**Codebook**")
  ) %>%
  tab_style(
    style = cell_fill(color = "aliceblue"),
    locations = cells_body(
      rows = Variable %in% c("Age", "Race", "Marital", "Now going to school or not?", "Persons in Household", "Elderly age>65 in Household", "Income: family income"))
  ) %>%
  tab_style(
    style = cell_fill(color = "skyblue"),
    locations = cells_body(
      rows = !(Variable %in% c("Age", "Race", "Marital", "Now going to school or not?", "Persons in Household", "Elderly age>65 in Household", "Income: family income"))
    )
  ) %>%
  tab_options(
    table.font.size = px(13L)
  )
```

```{r cleaning dataset}
# Predictors -- Demographics
# 1) age (1=Adolescent: 18-, 2=Young Adult: 18-29, 3=Middle Age: 30-64, 4=Elderly: 65+)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(age = case_when(AGE3 %in% c(1:3) ~ 1,
                         AGE3 %in% c(4:8) ~ 2,
                         AGE3 %in% c(9:10) ~ 3,
                         TRUE ~ 4))
# 2) sex (0=Female, 1=Male)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(sex = if_else(irsex == 2,0,1))

# 3) race (1=NonHisp White, 2=NonHisp Black/Afr Am, 3=NonHisp Native Am/AK Native, 4=NonHisp Native HI/Other Pac Isl, 5=NonHisp Asian, 6=NonHisp more than one race, 7=Hispanic)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(race = NEWRACE2)
  #mutate(race = case_when(NEWRACE2 %in% c(2:6) ~ 2,
                         # NEWRACE2 == 7 ~ 3,
                          #TRUE ~ 1))

# 4) health (0=w/o health problem: excellent/very good/good, 1=with health problem: fair/poor)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(health = case_when(health %in% c(1:3) ~ 0,
                            health %in% c(4:5) ~ 1,
                            TRUE ~ NA))

# 5) marital (0=never been married/cannot married<=14, 1=married, 2=widowed/divorced/separated)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(marital = case_when(irmarit %in% c(4,99) ~ 0,
                             irmarit %in% c(2:3) ~ 2,
                             TRUE ~ 1))

# Predictors -- Education
# 6) degree (1=w/o high school, 2=high school degree, 3=associate's degree/college graduate or higher)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(degree = case_when(IREDUHIGHST2 %in% c(1:7) ~ 1,
                            IREDUHIGHST2 %in% c(8:9) ~ 2,
                            TRUE ~ 3))

# 7) Now going to school or not? (1/11 = now going to school,  0=No, other is NA)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(student = case_when(eduschlgo %in% c(1, 11) ~ 1,
                             eduschlgo == 2 ~ 0,
                             TRUE ~ NA))

# Predictors: Employment and Houshold Composition
# 8) employ (1=employed full time, 2=employed part time, 3=unemployed, 4=Other(incl. not in labor force))
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(employ = case_when(WRKSTATWK2 %in% c(1,6) ~ 1,
                            WRKSTATWK2 %in% c(2:3) ~ 2,
                            WRKSTATWK2 %in% c(4,9) ~ 3,
                            TRUE ~ 4))

# 9) persons in household (range 1-5, 6=6 or more people in household)
NSDUH_2022_full <- NSDUH_2022_full %>% mutate(family = IRHHSIZ2)

# 10) kids age<18 in Household
# 0 = No children under 18 
# 1 = One child under 18
# 2 = Two children under 18 
# 3 = Three or more children under 18.
NSDUH_2022_full <- NSDUH_2022_full %>% mutate(kid = IRKI17_2 - 1)

# 11) elderly age>65 in Household (range 0-1, 2=2 or more elders in household)
# 0 = No people 65 or older in household
# 1 = One person 65 or older in household
# 2 = Two or more people 65 or older in household
NSDUH_2022_full <- NSDUH_2022_full %>% mutate(elderly = IRHH65_2-1)

# Predictors: Health and Income 
# 12) health_insur (0=w/o health insurance, 1=health insurance)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(health_insur = case_when(
    irmedicr == 1 | irmcdchp == 1 | irchmpus == 1 | irprvhlt == 1 ~ 1,
    irothhlt == 1 ~ 1,
    irothhlt == 2 ~ 0,
    irothhlt == 99 ~ NA,
    TRUE ~ 0
  ))

# 13) income: family income (1=poverty:20000-, 2=middle:74999-, 3=wealth:75000+)
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(income = case_when(IRFAMIN3 %in% c(1:2) ~ 1,
                            IRFAMIN3 %in% c(3:6) ~ 2,
                            TRUE ~ 3))

# 14) mentalhealth: combined score of K6 questions (range = 0 - 24, na:Aged 12-17) 
NSDUH_2022_full <- NSDUH_2022_full %>% 
  mutate(k1 = case_when(IRDSTCHR30 == 1 ~ 4,
                         IRDSTCHR30 == 2 ~ 3,
                         IRDSTCHR30 == 3 ~ 2,
                         IRDSTCHR30 == 4 ~ 1,
                         IRDSTCHR30 == 5 ~ 0,
                         TRUE ~ 99),
         k2 = case_when(IRDSTEFF30 == 1 ~ 4,
                         IRDSTEFF30 == 2 ~ 3,
                         IRDSTEFF30 == 3 ~ 2,
                         IRDSTEFF30 == 4 ~ 1,
                         IRDSTEFF30 == 5 ~ 0,
                         TRUE ~ 99),
         k3 = case_when(IRDSTHOP30 == 1 ~ 4,
                         IRDSTHOP30 == 2 ~ 3,
                         IRDSTHOP30 == 3 ~ 2,
                         IRDSTHOP30 == 4 ~ 1,
                         IRDSTHOP30 == 5 ~ 0,
                         TRUE ~ 99),
         k4 = case_when(IRDSTNGD30 == 1 ~ 4,
                         IRDSTNGD30 == 2 ~ 3,
                         IRDSTNGD30 == 3 ~ 2,
                         IRDSTNGD30 == 4 ~ 1,
                         IRDSTNGD30 == 5 ~ 0,
                         TRUE ~ 99),
         k5 = case_when(IRDSTNRV30 == 1 ~ 4,
                         IRDSTNRV30 == 2 ~ 3,
                         IRDSTNRV30 == 3 ~ 2,
                         IRDSTNRV30 == 4 ~ 1,
                         IRDSTNRV30 == 5 ~ 0,
                         TRUE ~ 99),
         k6 = case_when(IRDSTRST30 == 1 ~ 4,
                         IRDSTRST30 == 2 ~ 3,
                         IRDSTRST30 == 3 ~ 2,
                         IRDSTRST30 == 4 ~ 1,
                         IRDSTRST30 == 5 ~ 0,
                         TRUE ~ 99),
         mentalhealth = case_when(k1 == 99 | k2 == 99 | k3 == 99 | k4 == 99 | 
                                    k5 == 99 | k6 == 99 ~  NA,
                                  TRUE ~ k1+k2+k3+k4+k5+k6))
# For each of the six items listed above, responses of "all of the time" were coded 4, 
#"most of the time" were coded 3, "some of the time" were coded 2, "a little of the time" 
#were coded 1, and "none of the time" were coded 0. These assigned values were summed 
#across the six items to calculate a total score for mentalhealth.

# Create new dataset and drop all the NA values
data_cleaned <- NSDUH_2022_full %>%
  select(age, sex, race, health, marital, degree, 
         student, employ, family, kid, elderly, health_insur, 
         income, mentalhealth, SUD_MJ) %>%
  drop_na()
# check NAs
# anyNA(data_cleaned)
# New csv file
# write_csv(data_cleaned,"/Users/jiashuliu/Desktop/Projects/substance_use_disorder/data/sud_2022.csv")
```

# Exploratory Data Analysis

### Data Visualization

**Age**:
The age variable is categorized into four levels: "Adolescent" (under 18), "Young Adult" (18 to 29), "Middle Age" (30 to 64), and "Elderly" (65 and older). The plot shows the percentage of individuals within each age group who either have (SUD_MJ = 1) or do not have (SUD_MJ = 0) marijuana use disorder.

Among young adults (18 to 29 years), 20.6% of the respondents have marijuana use disorder, and 79.4% do not. In the middle-age group (30 to 64 years), 9.9% of respondents have marijuana use disorder, while 90.1% do not. In the elderly group (65+ years), only 2.5% of the respondents have marijuana use disorder, and 97.5% do not. The filtered survey data reveals that, at least in 2022, no adolescents are reported to have marijuana use disorder. The young adult group has the highest percentage of respondents with marijuana use disorder among the three age groups.

```{r}
# age (1=Adolescent: 18-, 2=Young Adult: 18-29, 3=Middle Age: 30-64, 4=Elderly: 65+)

# Calculate the percentage of SUD_MJ for each sex and each level of SUD_MJ
percentage_age <- sud_2022 %>%
  group_by(age, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

percentage_age <- percentage_age %>%
  mutate(age = factor(age, levels = c(1, 2, 3, 4), labels = c("Adolescent", "Young Adult", "Middle Age","Elderly")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))

p1.1 <- sud_2022 %>% 
  ggplot(aes(x = factor(age, levels = 1:4, labels = c("Adolescent", "Young Adult", "Middle Age","Elderly")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "age", y = "Count") +
  theme_minimal()+
  geom_text(data = percentage_age, aes(x = age, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p1.1
```

**Sex**:
The sex variable is categorized into two groups -- Female and Male. The plot shows the percentage of individuals within each sex group who either have (SUD_MJ = 1) or do not have (SUD_MJ = 0) marijuana use disorder. From the bar plot, we can see that the percentage of males with a marijuana use disorder in 2022 is slightly higher than that of females, with 17% of males having a marijuana use disorder and 12.5% of females having a marijuana use disorder.

```{r}
# Calculate the percentage of SUD_MJ for each sex and each level of SUD_MJ
percentage <- sud_2022 %>%
  group_by(sex, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

percentage <- percentage %>%
  mutate(sex = factor(sex, levels = c(0, 1), labels = c("Female", "Male")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))

# Plot SUD_MJ percentages in each gender group
p2 <- sud_2022 %>%
  ggplot(aes(x = factor(sex, levels = c(0, 1), labels = c("Female", "Male")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"), name = "SUD_MJ") +
  labs(x = "Sex", y = "Count") +
  theme_minimal() +
  geom_text(data = percentage, aes(x = sex, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)

p2
```

**Race**:
The following table summarizes the distribution of marijuana use disorder (SUD_MJ) among different racial groups. The count and percentage are provided for each combination of race and SUD_MJ status. The "NonHisp Asian" group has the lowest percentage (5.2%) of individuals with SUD_MJ, while the "NonHisp Native Am/AK Native" group has the highest percentage (27.3%). The "NonHisp White" group has the second-lowest percentage (13.7%) of individuals with SUD_MJ, and the "NonHisp More Than One Race" group has the second-highest percentage (23.1%). The "NonHisp Black/Afr Am" group has a percentage of 17.9% of individuals with SUD_MJ, which is higher than the "Hispanic" group, which has 15.1% of individuals with SUD_MJ.

```{r}
race_dat <- sud_2022 %>%
  mutate(race = factor(race, levels = 1:7, labels = c("NonHisp White", "NonHisp Black/Afr Am", "NonHisp Native Am/AK Native", "NonHisp Native HI/Other Pac Isl", "NonHisp Asian", "NonHisp more than one race", "Hispanic")))
race_summary <- race_dat %>%
  group_by(race, SUD_MJ) %>%
  summarize(count = n(), .groups = 'drop') %>%
  group_by(race) %>%
  mutate(percentage = round(count / sum(count) * 100, 1)) %>%
  ungroup()
highlighted_table <- race_summary %>%
  gt() %>%
  tab_style(
    style = cell_fill(color = "lightyellow"),
    locations = cells_body(
      rows = race == "NonHisp Native Am/AK Native" & SUD_MJ == 1
    )
  ) %>% 
  tab_style(
    style = cell_fill(color = "honeydew"),
    locations = cells_body(
      rows = race == "NonHisp Asian" & SUD_MJ == 1
    )
  )
highlighted_table
```

**Health**:
The health variable is categorized into two groups: with and without health problems. The bar plot shows that individuals with health problems have a higher percentage (20.7%) of SUD_MJ compared to those without health problems (13.6%). Please note that the survey data did not specify the specific health problems for individuals who rate their health as fair/poor, and we are not inferring any causal relationship between any potential health problem and marijuana use disorder here. 

```{r}
# health (0=w/o health problem: excellent/very good/good, 1=with health problem: fair/poor)
health_percentage <- sud_2022 %>%
  group_by(health, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

health_percentage <- health_percentage %>%
  mutate(health = factor(health, levels = c(0, 1), labels = c("w/o health problem", "with health problem")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))
p3 <- sud_2022 %>% ggplot(
  aes(x = factor(health, levels = 0:1, labels = c("w/o health problem", "with health problem")),
      fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Health", y = "Count") +
  theme_minimal()+
  geom_text(data = health_percentage, aes(x = health, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p3
```

**Marital**:
The variable "Marital" is categorized into three groups: "Never married," "Married," and "Widowed/Divorced." The percentages of individuals with and without SUD_MJ are displayed on the bars within each group.

- Among those who have never married, 21.9% have a marijuana use disorder, while 78.1% do not. 
- For married individuals, 7.2% have a marijuana use disorder, while a substantial 92.8% do not. 
- In the widowed/divorced group, 11.6% have a marijuana use disorder, whereas 88.4% do not. 

The plot highlights that the highest percentage of marijuana use disorder is found among those who have never married, followed by the widowed/divorced group. Married individuals have the lowest percentage of marijuana use disorder.

```{r}
# marital (0=never been married/cannot married<=14, 1=married, 2=widowed/divorced/separated)
marital_percentage <- sud_2022 %>%
  group_by(marital, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)
marital_percentage <- marital_percentage %>%
  mutate(marital = factor(marital, levels = c(0, 1, 2), labels = c("Never married", "Married", "Widowed/Divorced")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))
p4 <- sud_2022 %>% ggplot(
  aes(x = factor(marital, levels = 0:2, labels = c("Never married", "Married", 
                                                   "Widowed/Divorced")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Marital", y = "Count") +
  theme_minimal() + 
  geom_text(data = marital_percentage, aes(x = marital, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p4
```

**Education**:
The bar plot on the left displays the distribution of marijuana use disorder (SUD_MJ) among individuals with different educational levels. The variable "degree" shows the highest degree repsondents obtained, and is categorized into three groups: "without high school degree", "high school degree", and "higher (associate's degree/college graduate or higher)". The percentages of individuals with and without SUD_MJ within each educational group are displayed on the bars.

- Among individuals without a high school degree, 18.6% have a marijuana use disorder, while 81.4% do not.
- For individuals with a high school degree, 18.2% have a marijuana use disorder, while 81.8% do not.
- Among individuals with higher education, 9.7% have a marijuana use disorder, whereas 90.3% do not.

In summary, the plot on the left highlights that individuals with higher education have the lowest percentage (9.7%) of marijuana use disorder, whereas individuals without a high school degree and those with a high school degree have similar higher percentages (18.6% and 18.2%, respectively)

I took a closer look at the distribution of marijuana use disorder (SUD_MJ) among students currently attending school compared to those who are not. The data reveals that a significant majority of individuals not currently attending school do not have a marijuana use disorder, with the 'No' group predominantly represented by individuals without SUD_MJ.
```{r}
# degree (1=w/o high school, 2=high school degree, 3=associate's degree/college graduate or higher)
educ_percentage <- sud_2022 %>%
  group_by(degree, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)
educ_percentage <- educ_percentage %>%
  mutate(marital = factor(degree, levels = c(1, 2, 3), labels = c("w/o high school", "High school", "Higher")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))
p5 <- sud_2022 %>% ggplot(
  aes(x = factor(degree, levels = 1:3, labels = c("w/o high school", "High school", 
                                                   "Higher")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Degree", y = "Count") +
  theme_minimal()+
  geom_text(data = educ_percentage, aes(x = marital, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p5

#  Now going to school or not? (1/11 = now going to school,  0=No, other is NA)
p5.1 <- sud_2022 %>%
  ggplot(aes(x = factor(student, levels = c(0, 1), labels = c("No", "Yes")), fill = factor(student))) +
  geom_bar(alpha = 0.7) +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") + 
  labs(x = "Now Going to School", y = "Count") +
  theme_minimal()
p5.1
grid.arrange(p5, p5.1, ncol = 2, widths = c(2, 1))
```

**Employment**:
This bar plot illustrates the distribution of marijuana use disorder (SUD_MJ) among individuals with different employment statuses: "Full time," "Part time," "Unemployed," and "Other." 

- Among individuals employed full-time, 14.1% have a marijuana use disorder, while 85.9% do not.
- For those employed part-time, 16.8% have a marijuana use disorder, while 83.2% do not.
- Among unemployed individuals, 20.1% have a marijuana use disorder, whereas 79.9% do not.
- In the "Other" employment category, 9.2% have a marijuana use disorder, while 90.8% do not.

The plot highlights that the highest percentage of marijuana use disorder is found among unemployed individuals (20.1%), followed by those employed part-time (16.8%). Individuals employed full-time and those in the "Other" employment category have lower percentages of marijuana use disorder, with the "Other" category having the lowest percentage (9.2%).
```{r} 
# employ (1=employed full time, 2=employed part time, 3=unemployed, 4=Other(incl. not in labor force))
employ_percentage <- sud_2022 %>%
  group_by(employ, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)
employ_percentage <- employ_percentage %>%
  mutate(marital = factor(employ, levels = c(1, 2, 3, 4), labels = c("Full time", "Part time", 
                                                   "Unemployed", "Other")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))
p6 <- sud_2022 %>% ggplot(
  aes(x = factor(employ, levels = 1:4, labels = c("Full time", "Part time", 
                                                   "Unemployed", "Other")), 
      fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Employ", y = "Count") +
  theme_minimal()+
  geom_text(data = employ_percentage, aes(x = employ, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p6
```

**Income**:
This bar plot illustrates the distribution of marijuana use disorder (SUD_MJ) among individuals with different family income levels: "Poverty," "Middle," and "Wealth." 

- Among individuals in the "Poverty" income group, 20.9% have a marijuana use disorder, while 79.1% do not.
- For individuals in the "Middle" income group, 16.2% have a marijuana use disorder, while 83.8% do not.
- Among individuals in the "Wealth" income group, 10.1% have a marijuana use disorder, whereas 89.9% do not.

The result shows that the highest percentage of marijuana use disorder is found among individuals in the "Poverty" income group (20.9%), followed by those in the "Middle" income group (16.2%). Individuals in the "Wealth" income group have the lowest percentage of marijuana use disorder (10.1%).
```{r}
income_percentage <- sud_2022 %>%
  group_by(income, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)
income_percentage <- income_percentage %>%
  mutate(marital = factor(income, levels = c(1, 2, 3), labels = c("Poverty", "Middle", "Wealth")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))
p9 <- sud_2022 %>% ggplot(
  aes(x = factor(income, levels = 1:3, labels = c("Poverty", "Middle", "Wealth")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Family Income", y = "Count") +
  theme_minimal()+
  geom_text(data = income_percentage, aes(x = income, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p9
```

**Health Insurance**:
This last bar plot illustrates the distribution of marijuana use disorder (SUD_MJ) among individuals with and without health insurance. The percentages of individuals with and without SUD_MJ within each health insurance group are displayed on the bars.

- Among individuals without health insurance, 19.6% have a marijuana use disorder, while 80.4% do not.
- For individuals with health insurance, 13.9% have a marijuana use disorder, whereas 86.1% do not.

The result highlights that the highest percentage of marijuana use disorder is found among individuals without health insurance (19.6%). In contrast, those with health insurance have a lower percentage of marijuana use disorder (13.9%).
```{r}
# health_insur (0=w/o health insurance, 1=health insurance)
insur_percentage <- sud_2022 %>%
  group_by(health_insur, SUD_MJ) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

insur_percentage <- insur_percentage %>%
  mutate(health_insur = factor(health_insur, levels = c(0, 1), labels = c("w/o insurance", "insurance")),
         SUD_MJ = factor(SUD_MJ, levels = c(0, 1), labels = c("0", "1")))

p10 <- sud_2022 %>% ggplot(
  aes(x = factor(health_insur, levels = c(0, 1), labels = c("w/o insurance", "insurance")), fill = factor(SUD_MJ))) +
  geom_bar(alpha = 0.5, position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF595E"),name = "SUD_MJ") +
  labs(x = "Health Insurance", y = "Count") +
  theme_minimal()+
  geom_text(data = insur_percentage, aes(x = health_insur, y = count, label = paste0(round(percentage, 1), "%")),
            position = position_dodge(width = 0.9), vjust = -0.5)
p10
```

### Hypothesis Testing

In this section, I performed Chi-squared tests for all categorical variables against the marijuana use disorder (SUD_MJ) variable to test for independence. All variables in the sud_2022 dataset are converted to factors to ensure they are treated as categorical. For each categorical variable, a Chi-squared test of independence is conducted against SUD_MJ.

The Chi-squared test evaluates whether there is a significant association between each categorical variable and SUD_MJ. A p-value is obtained from each test, and variables with p-values less than 0.05 are considered significantly associated with SUD_MJ. 

The table shows that all tested variables (age, sex, race, health, marital status, degree, student status, employment, family, and presence of children) have p-values less than 0.05, indicating significant associations with SUD_MJ. However, the Chi-squared tests performed in this step only assess the independence of each individual categorical variable with respect to the marijuana use disorder (SUD_MJ) variable. Note that these tests do not provide information about the correlations or associations between the predictor variables themselves.

```{r}
sud_2022 <- sud_2022 %>%
  mutate_all(as.factor)
cate_var <- sud_2022 %>% select(-c(SUD_MJ))
variables <- names(cate_var)

# Perform Chi-squared Test
chi_square_test <- function(data, var) {
  tbl <- table(data[[var]], data[['SUD_MJ']])
  test <- chisq.test(tbl)
  p_value <- test$p.value
  data.frame(
    Variable = var,
    P_Value = p_value
  )
}

results <- lapply(variables, function(var) {
  chi_square_test(sud_2022, var)
})

# Combine the results 
results_df <- do.call(rbind, results)
results_df
```

# Model Fitting

In the model fitting section, I used the cleaned dataset, sud_2022, with selected predictors. Before applying the machine learning classification models, I first examined the outcome variable, marijuana use disorder (SUD_MJ). The outcome shows that our data is highly imbalanced, with 15% of individuals having SUD_MJ = 'Yes' and 85% having SUD_MJ = 'No'. Given this imbalance, when interpreting and evaluating the model performance, I will focus not only on overall accuracy but also on metrics such as AUC, sensitivity, and specificity to ensure a more comprehensive assessment.

To prepare for model training and testing, I split the dataset into 67% for training and 33% for testing. To avoid overfitting, I implemented a 10-fold cross-validation approach, which will be applied later in the models. This method helps ensure that the model generalizes well to unseen data by validating its performance across multiple subsets of the training data.

```{r train-test split}
# Load in dataset
NSDUH_2022 <- read.csv("/Users/jiashuliu/Desktop/Projects/substance_use_disorder/data/sud_2022.csv")
# Convert all the variables into factors
NSDUH_2022 <- NSDUH_2022 %>% 
   mutate(across(where(is.numeric), as.factor))
str(NSDUH_2022)
sud_mj_yes <- subset(NSDUH_2022, SUD_MJ == 1)
sud_mj_no <- subset(NSDUH_2022, SUD_MJ == 0)
ratio_yes <- nrow(sud_mj_yes) / nrow(NSDUH_2022)
ratio_no <- nrow(sud_mj_no) / nrow(NSDUH_2022)

# # NSDUH_2022 is an imbalanced dataset
cat("Ratio of SUD_MJ = Yes:", round(ratio_yes, 2), "\n")
cat("Ratio of SUD_MJ = No:", round(ratio_no, 2), "\n")

set.seed(123)
# Split data in 67% train/ 33% test sets
split_size <- sample(1:nrow(NSDUH_2022), floor(0.67 * nrow(NSDUH_2022)))
training <- NSDUH_2022[split_size, ]
testing <- NSDUH_2022[-split_size, ]

# Change the levels of SUD_MJ from 0 and 1 to 'No' and 'Yes'. Otherwise this will lead to errors in trainControl
levels(training$SUD_MJ) <- c("No", "Yes")
levels(testing$SUD_MJ) <- c("No", "Yes")
```
Before actually fitting the model, I transformed the categorical variables into into binaries where each category is represented by a separate binary feature using one-hot encoding techinque. I will used the one-hot encoding dataset for the logistic regression and GBM prediction in the later section. 

However, it is important to note that the random forest model does not require one-hot encoding. Random forests can handle categorical variables directly by splitting nodes based on the original categorical values. In fact, I found that applying one-hot encoding to the random forest model can make its performance worse. This degradation might be due to the increased dimensionality and sparsity introduced by one-hot encoding, making it harder for the random forest to find the optimal splits. 
 
Therefore, for the random forest model, I retained the original categorical variables without applying one-hot encoding. This approach leverages the inherent capability of random forests to handle categorical data effectively and maintains the model's performance.

```{r}
# One-hot encoding for categorical variables
train_matrix <- model.matrix(SUD_MJ ~ . - 1, data = training)[, -1]
test_matrix <- model.matrix(SUD_MJ ~ . - 1, data = testing)[, -1]
train <- as.data.frame(train_matrix)
test <- as.data.frame(test_matrix)

# Ensure that the target variable SUD_MJ is included
train$SUD_MJ <- training$SUD_MJ
test$SUD_MJ <- testing$SUD_MJ
```
### 1. Logistic Regression

A logistic regression model is used to predict the probability of a binary outcome based on one or more predictor variables. It is widely utilized for classification tasks where the outcome variable is categorical with two possible outcomes. I began with logistic regression because it is straightforward and highly interpretable, making it an excellent baseline model for comparison against more complex models

#### Model Performance 

After fitting the logistic regression model to the training data and making predictions on the test data, I evaluated the model's performance using a confusion matrix and various performance metrics. 

- Accuracy: The model achieved an accuracy of 85.26%, indicating that in general, 85.26% of the predictions made by the model were correct.
- Sensitivity: The sensitivity, also called recall rate, in this model is very low at 3.93%, indicating that the model struggled to correctly identify individuals with SUD_MJ. 
- Specificity: The specificity is 99.19%, meaning that the model correctly identified 99.19% of the individuals who do not have SUD_MJ.
- Precision: The precision, or positive predictive value, is about 45%, meaning that when the model predicts 'Yes' for SUD_MJ, it is correct 45.26% of the time. Therefore, we call also tell that there are a substantial amount of false positives. 
- F1-Score: The F1-score is 7%, which is a measure of the balance between recall/sensitifity and the precision. A very low F-1 score further indicates that the logistic regression model has limited ability of identifying positive cases. 
- AUC: The AUC is 0.76, indicating that the model has a fair ability to distinguish between the two classes.

The model demonstrates high specificity but extremely low sensitivity, meaning it is highly effective at identifying individuals without marijuana use disorder but fails significantly in identifying those with the disorder. The accuracy of 85.26% is misleading due to the class imbalance, as it closely mirrors the baseline accuracy of always predicting the majority class ('No'). The sensitivity,  specificity and F-1 score highlight the model's limitations in dealing with the minority class ('Yes'). In this case, AUC is a more reliable measure of the overall performance of the model given in context of imbalanced data. An AUC of 0.76 suggests the model has a moderate ability in distinguishing the positive and negative classes. In general, these model performance metrics suggest that while the model performs well overall due to the high prevalence of 'No' cases, it requires improvements, particularly in its ability to correctly identify and predict instances of marijuana use disorder. 

```{r train logistic reg}
set.seed(123)
# 10-folds cross-validation
trControl <- trainControl(method = "cv", 
                          number = 10, 
                          classProbs = TRUE, 
                          summaryFunction = twoClassSummary)

# Train the logistic regression model using cv
logistic_cv <- caret::train(SUD_MJ ~ ., 
                            data = train, 
                            method = "glm", 
                            family = binomial, 
                            trControl = trControl, # using cv to avoid overfitting
                            metric = "ROC")
summary(logistic_cv)

# Make predictions on the testing set
prob.logi <- predict(logistic_cv, newdata = test, type = "prob")[, "Yes"]
pred.logi <- ifelse(prob.logi > 0.5, "Yes", "No")
pred.logi <- factor(pred.logi, levels = c("No", "Yes"))

confusion_matrix_logistic <- confusionMatrix(pred.logi, test$SUD_MJ, positive = "Yes")
print(confusion_matrix_logistic)
# Accuracy
accuracy_logi <- confusion_matrix_logistic$overall['Accuracy']
print(paste("Accuracy:", round(accuracy_logi, 2)))
# Precision, Sensitivity, Specificity, and F1-Score
sensitivity_logi <- confusion_matrix_logistic$byClass['Sensitivity']
specificity_logi <- confusion_matrix_logistic$byClass['Specificity'] 
precision_logi <- confusion_matrix_logistic$byClass['Pos Pred Value']
F1_score_logi <- 2 * ((precision_logi * sensitivity_logi) / (precision_logi + sensitivity_logi))
print(paste("Sensitivity:", round(sensitivity_logi, 2)))
print(paste("Specificity:", round(specificity_logi, 2)))
print(paste("Precision:", round(precision_logi, 2)))
print(paste("F1-Score:", round(F1_score_logi, 2)))
# AUC
pred <- prediction(prob.logi, test$SUD_MJ)
perf_auc <- performance(pred, measure = "auc")
auc_value <- perf_auc@y.values[[1]]
print(paste("AUC:", round(auc_value, 2)))
# Plot ROC Curve
perf_roc <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf_roc, main = "ROC Curve", col = "red", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
```

### 2. Lasso logistic Regression

Next, I initiated a Lasso logistic regression. The Lasso penalty term shrinks the coefficients of the less important variables to zero, effectively performing variable selection. I first trained the Lasso logistic regression model using 10-fold cross-validation to find the optimal lambda value that minimizes the mean cross-validation error. After determining the optimal lambda, I fit the final model using this value and made predictions on the test data. This approach helps to enhance the model's performance by focusing only on the most relevant predictors and reducing overfitting.

#### Model Performance 

- Accuracy: The model achieved an overall accuracy of 85.38%, indicating that 85.38% of the total predictions were correct. 

- Sensitivity: The sensitivity (or recall) is extremely low at 0.000457, meaning that the model correctly identified only a very small fraction of the actual 'Yes' cases. In the confusion matrix, the model actually only identified 1 true positive instances. 

- Specificity: The specificity, on the other hand, is very high at 0.99, meaning that the model correctly identifying most of the negative cases. 

- Precision: The precision is about 50%, meaning that when the model predicts 'Yes' for SUD_MJ, it is correct only 50% of the time, which is no better than a random guess.

Overall, the Lasso logistic regression model shows poor performance. Despite having high accuracy and a decent AUC, the extremely low sensitivity and extremely high specificity indicate a poor detection of positive cases. This outcome suggests that the model heavily favors predicting the majority class ('No') and struggles to identify true positive instances of marijuana use disorder. 

```{r}
set.seed(123)
CVlasso <- cv.glmnet(train_matrix, 
                     train$SUD_MJ, 
                     type.measure = "class", 
                     family = "binomial", 
                     alpha = 1, 
                     nfolds = 10)
p1 <- plot(CVlasso)
p2 <- plot(CVlasso$glmnet.fit, 
     "lambda", label=FALSE)
lambda_1se <- CVlasso$lambda.1se
lambda_min <- CVlasso$lambda.min
print(paste("Lambda.1se: ", lambda_1se))
print(paste("Lambda.min: ", lambda_min))
coef(CVlasso, s = lambda_min)
# coef(CVlasso, s = lambda_1se) # Only intercept left if using lamba 1se

# Final model with lambda.min
lasso.model <- glmnet(train_matrix, train$SUD_MJ, alpha = 1, family = "binomial",
                      lambda = lambda_min, nfolds = 10)
dim(test_matrix)
dim(train_matrix)
# Make prediction on test data
prob.lasso <- predict(lasso.model, newx = test_matrix, type = "response")
pred.lasso <- ifelse(prob.lasso > 0.5, "Yes", "No")
confusion_matrix_lasso <- confusionMatrix(as.factor(pred.lasso), test$SUD_MJ, positive = "Yes")
print(confusion_matrix_lasso)

# Accuracy
accuracy_lasso <- confusion_matrix_lasso$overall['Accuracy']
print(paste("Accuracy:", round(accuracy_lasso, 2)))
# Sensitivity 
sensitivity_lasso <- confusion_matrix_lasso$byClass['Sensitivity']
print(paste("Sensitivity:", sensitivity_lasso))
# Specificity
specificity_lasso <- confusion_matrix_lasso$byClass['Specificity']
print(paste("Sensitivity:", specificity_lasso))
# Precision
precision_lasso <- confusion_matrix_lasso$byClass['Pos Pred Value']
print(paste("Precision:", precision_lasso))
# F-1 Score
F1_lasso <- 2 * ((precision_lasso * sensitivity_lasso) / (precision_lasso + sensitivity_lasso))
print(paste("F-1 Score:", F1_lasso))
# AUC
pred <- prediction(prob.lasso, test$SUD_MJ)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
auc_lasso <- performance(pred, measure = "auc")@y.values[[1]]
print(paste("AUC: ", auc_lasso))
plot(perf, main = "ROC Curve for Lasso Regression", col = "blue", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
```

The model has identified several key predictors of marijuana use disorder.The variable importance is ranked based on the absolute values of the coefficients. The top 5 predictors include age, mental health, race, marital, and sex.

**age**: age4 (elderly 65+) has the highest importance. A coefficient of -1.38 for age4 means that for individuals in the "Elderly" age category, the log-odds of having marijuana use disorder decrease by 1.3809210453 units on average compared to the reference age category, holding all other variables constant.

**mental health**: Several mental health related predictors are categorized as important predictors, such as mentalhealth20, mentalhealth24, mentalhealth18, mentalhealth22, mentalhealth16, mentalhealth14, mentalhealth21, mentalhealth15, mentalhealth12, and mentalhealth23. The positive coefficients of these predictors suggest that higher mental health issues are associated with an increased risk of marijuana use disorder.

**race**: race5 (Non-Hispanic Native Hawaiian/Other Pacific Islander) has a negative coefficients of -0.67, meaning that individuals identified as Non-Hispanic Native Hawaiian/Other Pacific Islander have log-odds of having marijuana use disorder that decrease by 0.67 units on average compared to the reference race category, holding all other variables constant.

**marital status**: Marital status (marital1) has a negative coefficient of -0.57, meaning that married individuals have log-odds of having marijuana use disorder that decrease by 0.57 units on average compared to non-married individuals, holding all other variables constant

**sex**:sex1 has a positive coefficient of 0.285, meaning that males have log-odds of having marijuana use disorder that increase by 0.285 units on average compared to females, holding all other variables constant.
```{r variable importance}
# Variable importance
coef_lasso <- coef(lasso.model, s = lambda_min)
coef_lasso <- as.data.frame(as.matrix(coef_lasso))
print(coef(lasso.model, s = lambda_min))
coef_lasso$variable <- rownames(coef_lasso)
colnames(coef_lasso)[1] <- "coefficient"

coef_lasso <- coef_lasso %>%
  filter(variable != "(Intercept)") %>%
  mutate(importance = abs(coefficient)) %>%
  arrange(desc(importance))
print(coef_lasso)
```


### 3. Random Forest

I further employed the random forest model to tackle the binary classification problem. Unlike logistic regression, which is a linear model, the random forest is a non-linear model capable of capturing more complex relationships between features. Additionally, the random forest model provides feature importance metrics, which help identify the most relevant features for the classification task.

The model was initially trained on the training data with 500 trees, and the number of variables tried at each split (mtry) was set to the optimal value found during tuning. The optimal mtry value was determined by tuning the model to minimize the Out-Of-Bag (OOB) error estimate. The OOB error estimate serves as an internal validation metric for the model, providing an unbiased estimate of the prediction error. The random forest model achieved a minimum OOB error rate of 14.45%, indicating that approximately 14.45% of the predictions made by the model on the training data were incorrect. I selected the mtry value that corresponded to the lowest OOB error rate for the final model.

```{r train rf}
# Train random forest model using training data 
set.seed(123)
rf_model<- randomForest(SUD_MJ ~ ., 
                        data = training, 
                        ntree = 500, 
                        importance = TRUE)
# Tune the Rf model by finding the optimal mtry value 
# Select mtry value with minimum out of bag(OOB) error
mtry <- tuneRF(training[, -ncol(training)],training$SUD_MJ, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)
```

In the next step, I refit the model using the best mtry value (mtry = 2), generate variable importance plots, and make predictions using the testing data. The variable importance plot highlights the most influential predictors in the Random Forest model. According to the Mean Decrease Accuracy and Mean Decrease Gini metrics, 'mentalhealth', 'age', 'race', 'marital', 'family', and 'employ' were among the most important variables for predicting SUD_MJ. The Mean Decrease Accuracy measures the reduction in model accuracy when a variable is excluded, while the Mean Decrease Gini indicates the total decrease in node impurity that a variable contributes across all trees in the forest.

```{r tune rf}
# Refit the model using best mtry
rf_tuned <- randomForest(SUD_MJ ~., data = training, ntree = 500, mtry = best.m, importance=TRUE)
print(rf_tuned)
importance(rf_tuned) 
varImpPlot(rf_tuned)
# Higher the value of mean decrease accuracy or mean decrease gini score , higher the importance of the variable in the model. In the plot shown blow, mental health is most important variable.
# Mean Decrease Accuracy - How much the model accuracy decreases if we drop that variable.
# Mean Decrease Gini - Measure of variable importance based on the Gini impurity index used for the calculation of splits in trees.
# Making predictions based on test data
pred_prob_rf_tuned <- predict(rf_tuned, newdata = testing, type = "prob")[, 2]
pred_class_rf_tuned <- ifelse(pred_prob_rf_tuned > 0.5, "Yes", "No")
# Print confusion matrix
confusion_matrix_rf_tuned <- confusionMatrix(as.factor(pred_class_rf_tuned), testing$SUD_MJ, positive = "Yes")
```

#### Model Performance

- Accuracy: Evaluating on the testing data, the Random Forest model achieved an overall prediction accuracy of 85.4%.
- Precision: The precision is 61.54%, meaning that when the model predicts 'Yes' for SUD_MJ, it is correct 61.54% of the time. 
- Sensitivity: The model correctly identified only 0.37% of the actual 'Yes' cases, indicating a poor ability to detect true positives.
- Specificity:  The model correctly identified 99.96% of the actual 'No' cases, showing that the model is good at detecting true negatives.
- F1-Score: The F1-Score is extremely low at 0.01, providing a balance between precision and recall. It further prove that the random forest has poor overall performance in handling the positive cases.
- AUC: The AUC for the random forest model is 0.72, indicating that the model has some discriminatory power, but it is not particularly strong.

Overall, the Random Forest model demonstrates high specificity and reasonable precision for the majority (SUD_MJ = 'No') class, but like the previous two models, it still struggles with detecting the minority class. The sensitivity is extremely low at 0.37%, indicating the model's poor ability to identify true positive cases of marijuana use disorder. The overall accuracy of 85.4% is driven by the correct classification of the majority 'No' class, which is expected given the high imbalance in the dataset.

The very low F1-Score and balanced accuracy further highlight the model's inability in handling the minority class (SUD_MJ = 'Yes'). The moderate AUC of 0.72 indicates some ability to distinguish between the classes, but I think it is not sufficient enough for reliable predictions. These results suggest the need for further adjustments or alternative modeling approaches to better address the class imbalance and improve the detection of true positive cases.

```{r rf perf}
# Accuracy
print(confusion_matrix_rf_tuned)
accuracy_rf_tuned <- confusion_matrix_rf_tuned$overall['Accuracy']
print(paste("Accuracy:", round(accuracy_rf_tuned, 2)))
# Precision, Recall, F1-Score
precision_rf_tuned <- confusion_matrix_rf_tuned$byClass['Pos Pred Value']
sensitivity_rf_tuned <- confusion_matrix_rf_tuned$byClass['Sensitivity']
specificity_rf_tuned <- confusion_matrix_rf_tuned$byClass['Specificity']
F1_rf_tuned <- 2 * ((precision_rf_tuned * sensitivity_rf_tuned) / (precision_rf_tuned + sensitivity_rf_tuned))
print(paste("Precision:", round(precision_rf_tuned, 2)))
print(paste("Sensitivity:", round(sensitivity_rf_tuned, 2)))
print(paste("Specificity:", round(specificity_rf_tuned, 2)))
print(paste("F1-Score:", round(F1_rf_tuned, 2)))
# AUC
pred_rf_tuned <- prediction(pred_prob_rf_tuned, testing$SUD_MJ)
auc_rf_tuned <- performance(pred_rf_tuned, "auc")
auc_value_rf_tuned <- auc_rf_tuned@y.values[[1]]
print(paste("AUC:", round(auc_value_rf_tuned, 2)))
# Plot ROC
roc_rf_tuned <- performance(pred_rf_tuned, measure = "tpr", x.measure = "fpr")
plot(roc_rf_tuned, main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```

### 4. Generalized Boosted Regression Model (GBM)

Lastly, I used a Generalized Boosted Regression Model (GBM). Unlike Random Forest, where each decision tree is built independently from each sample, the trees in GBM are built sequentially. Each tree corrects the errors made by the previous one, enhancing the overall model performance.

To optimize the performance of the GBM, I first performed hyperparameter tuning using a grid search. The model was then trained on the training data using 10-fold cross-validation to prevent overfitting. The most optimal GBM model hyperparameters were found to be: n.trees = 150, interaction.depth = 1, shrinkage = 0.3, and n.minobsinnode = 10. These values were selected because they produced the highest ROC value during cross-validation, indicating the model's strong ability to distinguish between individuals with and without SUD_MJ.

```{r tune gbm}
set.seed(123)
# Tune the hyperparameters
tuneGrid <- expand.grid(interaction.depth = c(1, 3, 5),  # Depth of each tree
                        n.trees = c(50, 100, 150),       # Number of trees
                        shrinkage = c(0.01, 0.1, 0.3),   # Learning rate
                        n.minobsinnode = c(10, 20))
# Fit gbm with train data
gbm_model <- caret::train(SUD_MJ ~ .,
                          data = train,
                          method = "gbm",
                          trControl = trControl,
                          tuneGrid = tuneGrid,
                          metric = "ROC",
                          verbose = FALSE)
best_params <- gbm_model$bestTune
print(best_params)
```
After training the GBM model with the best hyperparameters, I examined the variable importance again to understand which features were most influential in predicting SUD_MJ. The relative influence of the variables showed that 'Young Adult' (age2) and 'Married' (marital1) were the most important predictors, followed by 'Elderly: 65+' (age4), 'Associate's degree/college graduate or higher' (degree3), and 'Male' (sex1). Mental health-related variables (e.g., mentalhealth12, mentalhealth16, mentalhealth24) also showed significant importance. This analysis highlights the key factors that contribute to the prediction of marijuana use disorder, providing insights for further research and model improvement.

```{r gbm with best params}
# Convert outcome variable to numeric 0 and 1
train$SUD_MJ <- ifelse(train$SUD_MJ == "Yes", 1, 0)
test$SUD_MJ <- ifelse(test$SUD_MJ == "Yes", 1, 0)

# Train the gbm model again with best parameters
gbm_best <- gbm::gbm(SUD_MJ ~ .,
                      data = train,
                      distribution = "bernoulli",
                      n.trees = best_params$n.trees,
                      interaction.depth = best_params$interaction.depth,
                      shrinkage = best_params$shrinkage,
                      n.minobsinnode = best_params$n.minobsinnode,
                      cv.folds = 10,
                      keep.data = TRUE,
                      verbose = FALSE)
summary(gbm_best)
```

#### Model Performance

- Accuracy: The model correctly classified 85.43% of the instances overall.
- Precision: The model has a precision of 53.92%, meaning that when the model predicts 'Yes' for SUD_MJ, it is correct 53.92% of the time. 
- Sensitivity (Recall): The recall rate is 2.51%, indicating that the model only correctly identified 2.51% of the actual 'Yes' cases.
- Specificity: The model has a very high specificity at 99.63%, meaning that it has an excellent ability to detect true negatives.
- F-1 Score: The very low F1-Score (0.05) indicates poor overall performance in handling the positive class.
- AUC: An AUC of 0.76 indicates that the model has a moderate ability in distinguishing between 'Yes' and 'No'.
The GBM model has a high specificity and a reasonable precision for predicting the majority class (SUD_MJ = "No"). However, from the very low sensitivity, we can tell that the model also struggles with detecting the minority class (SUD_MJ = "Yes"). The overall accuracy is high at 85.43%, which is driven by the correct classification of the majority 'No' class. The low F1-Score and balanced accuracy highlight the model's ineffectiveness in handling the minority class. The moderate AUC of 0.76 indicates some ability to distinguish between the classes.

```{r gbm perf}
# Make predictions on the testing set
predicted_prob_gbm <- predict(gbm_best, newdata = test, n.trees = best_params$n.trees, type = "response")
predicted_class_gbm <- ifelse(predicted_prob_gbm > 0.5, 1, 0)

# Confusion matrix on the testing set
confusion_matrix_gbm <- confusionMatrix(as.factor(predicted_class_gbm), as.factor(test$SUD_MJ), positive = '1')
print(confusion_matrix_gbm)

# Accuracy
accuracy_gbm <- confusion_matrix_gbm$overall['Accuracy']
print(paste("Accuracy:", round(accuracy_gbm, 2)))
# Precision, Sensitivity, Specificity, F-1
precision_gbm <- confusion_matrix_gbm$byClass['Pos Pred Value']
sensitivity_gbm <- confusion_matrix_gbm$byClass['Sensitivity']
specificity_gbm <- confusion_matrix_gbm$byClass['Specificity']
f1_score_gbm <- 2 * ((precision_gbm * sensitivity_gbm) / (precision_gbm + specificity_gbm))

print(paste("Precision:", round(precision_gbm, 3)))
print(paste("Sensitivity:", round(sensitivity_gbm, 3)))
print(paste("Specificity:", round(specificity_gbm, 3)))
print(paste("F1-Score:", round(f1_score_gbm, 3)))

# AUC
pred_gbm <- prediction(predicted_prob_gbm, test$SUD_MJ)
perf_auc_gbm <- performance(pred_gbm, measure = "auc")
auc_value_gbm <- perf_auc_gbm@y.values[[1]]
print(paste("AUC:", round(auc_value_gbm, 2)))

# Plot the ROC curve
perf_roc_gbm <- performance(pred_gbm, measure = "tpr", x.measure = "fpr")
plot(perf_roc_gbm, main = "ROC Curve for GBM", col = "blue", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
```

# Model Comparison

To recap, four machine learning models were used to predict marijuana use disorder (SUD_MJ): Logistic Regression, Lasso Logistic Regression, Random Forest, and GBM.

Comparing all four models, logistic regression outperforms the other three, as it has the highest AUC of 0.76. Despite all models struggling to accurately identify positive cases (SUD_MJ = "Yes"), Logistic Regression performs slightly better than the others, with the highest sensitivity at 3.9%. Moreover, Logistic Regression has higher interpretability, making it easier to understand and explain the impact of each predictor on the outcome.

Overall, while no model demonstrated exceptional performance in identifying positive cases, Logistic Regression's superior AUC, higher sensitivity, and interpretability make it the preferred model for predicting marijuana use disorder in this study.

```{r}
metrics <- data.frame(
  Model = c("Logistic Regression","Lasso Logistic Regression", "Random Forest", "GBM"),
  Accuracy = c(accuracy_logi, accuracy_lasso, accuracy_rf_tuned, accuracy_gbm),
  Precision = c(precision_logi, precision_lasso, precision_rf_tuned, precision_gbm),
  Sensitivity = c(sensitivity_logi, sensitivity_lasso, sensitivity_rf_tuned, sensitivity_gbm),
  Specificity = c(specificity_logi,specificity_lasso, specificity_rf_tuned, specificity_gbm),
  F1_Score = c(F1_score_logi, F1_lasso, F1_rf_tuned, f1_score_gbm),
  AUC = c(auc_value, auc_lasso, auc_value_rf_tuned, auc_value_gbm)
  )
# metrics_table <- gt(metrics) %>%
#   tab_header(
#     title = md("**Model Performance Metrics**")
#   ) %>%
#   fmt_number(
#     columns = 2:7,
#     decimals = 4
#   ) %>%
#   cols_label(
#     Model = "Model",
#     Accuracy = "Accuracy",
#     Precision = "Precision",
#     Sensitivity = "Sensitivity",
#     Specificity = "Specificity",
#     F1_Score = "F1 Score",
#     AUC = "AUC"
#   ) %>%
#   tab_style(
#     style = list(
#       cell_fill(color = "lightblue"),
#       cell_text(weight = "bold")
#     ),
#     locations = cells_body(
#       columns = vars(Model)
#     )
#   ) %>%
#   tab_style(
#     style = cell_borders(
#       sides = "all",
#       color = "grey",
#       weight = px(1)
#     ),
#     locations = cells_body()
#   ) %>%
#   tab_options(
#     table.width = pct(100),
#     column_labels.font.weight = "bold"
#   )
print(metrics)
```

# Conclusion and Discussion 

In this project, I employed four models to estimate the probability that a user of marijuana products will develop marijuana use disorder and to identify the socio-demographic variables associated with this outcome. The results from all four models suggest that age, mental health, sex, marital status, education, and race are the most important variables out of the 14 initially selected. To avoid overfitting, I implemented 10-fold cross-validation for each model.

However, the reasons for marijuana use disorder are complex and multifaceted, varying widely between individuals. Our findings suggest that the selected socio-demographic variables might be relevant to marijuana use disorder, but more research is needed to understand the actual causes fully.

Comparing the AUC, sensitivity, specificity, precision, and F1 scores, the logistic regression model demonstrated better overall performance than the other three models. This indicates that more complex models do not always lead to better performance. Logistic regression's simplicity and interpretability make it a strong choice in this context.

One of the biggest limitations of this study is that the NSDUH 2022 survey dataset is inherently imbalanced. This imbalance poses a significant challenge for predictive modeling, as it can lead to biased results where the model performs well on the majority class but poorly on the minority class. Implementing either oversampling or undersampling techniques to address this imbalance can lead to a loss of valuable information. Oversampling might result in overfitting, while undersampling could omit crucial data points. Consequently, the imbalanced dataset makes accurate prediction more difficult and limits the generalizability of the model's findings. Future research should explore advanced techniques, such as synthetic data generation or ensemble methods, to mitigate these issues and enhance the model's robustness and accuracy.

# References